{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning\n"
     ]
    }
   ],
   "source": [
    "cd /Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (8.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/toshiniagrawal/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from scipy) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/toshiniagrawal/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (1.7.1)\n",
      "Requirement already satisfied: typing_extensions in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/toshiniagrawal/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Ipython in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (7.19.0)\n",
      "Requirement already satisfied: pickleshare in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (56.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (0.17.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (3.0.8)\n",
      "Requirement already satisfied: backcall in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (0.2.0)\n",
      "Requirement already satisfied: pygments in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (2.7.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (5.0.5)\n",
      "Requirement already satisfied: decorator in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (4.4.2)\n",
      "Requirement already satisfied: appnope in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from Ipython) (0.1.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.10->Ipython) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->Ipython) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->Ipython) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from traitlets>=4.2->Ipython) (0.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/toshiniagrawal/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: video-kf in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (0.0.3)\n",
      "Requirement already satisfied: requests>=2.22 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from video-kf) (2.24.0)\n",
      "Requirement already satisfied: opencv-python>=4 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from video-kf) (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from video-kf) (1.19.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.22->video-kf) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.22->video-kf) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.22->video-kf) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/toshiniagrawal/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.22->video-kf) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/toshiniagrawal/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install video-kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import videokf as vf\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Module.dump_patches = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_folder(Video_folder):\n",
    "    \n",
    "    os.makedirs(\"output11\")\n",
    "    try:\n",
    "        for i, Video_name in enumerate(os.listdir(Video_folder)):\n",
    "                #keyframe_folder = \"keyframes/\" + str(i)\n",
    "                print(Video_name)\n",
    "                vf.extract_keyframes(os.path.join(Video_folder, Video_name))\n",
    "                print(\"Extraction complete!!\")\n",
    "                for count, filename in enumerate(os.listdir(\"vdos/keyframes\")):\n",
    "                    str_name = filename.split('.')\n",
    "                    n = int(str_name[0])\n",
    "                    a = str(n/25)\n",
    "                    seconds_input, b = a.split('.')\n",
    "                    if len(b)==1:\n",
    "                        b = b + \"00\"\n",
    "                    elif len(b)==2:\n",
    "                        b = b + \"0\"\n",
    "                    else:\n",
    "                        b = b\n",
    "                    converted_time = datetime.timedelta(seconds=int(seconds_input))\n",
    "                    total = str(converted_time).split(\":\")\n",
    "                    total.append(b)\n",
    "                    hour = total[0]\n",
    "                    if len(hour)==1:\n",
    "                        hour = \"0\" + hour\n",
    "                    else:\n",
    "                        hour = hour\n",
    "                    total[0] = hour\n",
    "                    new_name = '-'.join(total)\n",
    "                    frame_loc = os.path.join(\"vdos/keyframes\", filename) \n",
    "                    \n",
    "                    dst = os.path.join(\"vdos/keyframes\", new_name) + \".jpg\" \n",
    "                    try :\n",
    "                        os.rename(frame_loc, dst)\n",
    "                        print(\"Source path renamed to destination path successfully.\")\n",
    "                    except IsADirectoryError:\n",
    "                        print(\"Source is a file but destination is a directory.\")\n",
    "                    except NotADirectoryError:\n",
    "                        print(\"Source is a directory but destination is a file.\")\n",
    "                    except PermissionError:\n",
    "                        print(\"Operation not permitted.\")\n",
    "                    except OSError as error:\n",
    "                        print(error)\n",
    "    \n",
    "                os.rename(\"vdos/keyframes\", \"output/\"+ Video_name.split(\".\")[0])\n",
    "                print(\"Folder successfully renamed\")\n",
    "    except:\n",
    "            print(\"exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mirzapur.mp4\n",
      "!!! The output directory 'keyframes' is not empty. No iframes were extracted. !!!\n",
      "Extraction complete!!\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "rename_folder(\"/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning/vdos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Module.dump_patches = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"caption.py\", line 241, in <module>\r\n",
      "    coco()\r\n",
      "  File \"caption.py\", line 208, in coco\r\n",
      "    decoder = checkpoint['decoder']\r\n",
      "TypeError: string indices must be integers\r\n"
     ]
    }
   ],
   "source": [
    "!python caption.py --img_folder='output/mirzapur' --model='BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar' --word_map='WORDMAP_coco_5_cap_per_img_5_min_word_freq.json' --beam_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning/caption2.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-a534fa3e81da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m    \u001b[0;31m# print(convert(word_list), sep=\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0munique_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-184-a534fa3e81da>\u001b[0m in \u001b[0;36munique_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munique_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning/caption2.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfile_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning/caption2.txt'"
     ]
    }
   ],
   "source": [
    "def unique_file():\n",
    "    input_file = open(r\"/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning/caption2.txt\", 'r')\n",
    "    file_contents = input_file.read()\n",
    "    input_file.close()\n",
    "    word_list = file_contents.split()\n",
    "    useless=['red','for','preparing','screen','line','lit','dimly','kinds','bikini','different','shaped','beautiful','pile','stop','stuffed','topped','neon','slicing','like','types','items','wooden','stack','small','many','sleeping','pairs','smile','short','silhouette','cooking','dark','legs','palm','light','smart','purple','kids','box','lot','other','open','signs','girls','brown','boys','herself','cat','various','tall','display','very','nintendo','near','board','covered','smiling','while','potted','large','lots','cutting','parked','train','small','blow','over','performing','horses','big','little','elephants','bear','drying','himself','blue','piece','sticker','some','furniture','filled','yellow','of','from','pink','through','reads','doorway','doing','table','middle','hand','court','posing','white','child','projection','beard','cloudy','cell','glass','flying','hot','plate','bench','plane','growing','silver','view','glasses','chair','shirt','out','persons','green','game','side','dining','bed','bears','remote','teeth','bat','game','video','flower','teddy','cap','hat','driving','suit','suits','little','tiled','book','mirror','black','start','is','sticking','flowers','rear','meter','tilted','skate','back','has','around','sign','desk','tongue','birds','clock','plane','room','himself','couch','control','giraffe','young','its','tennis','brushes','toothbrush','baseball','bird','across','racquet','people','bowl','bunch','clear','crowd','tooth','urinals','woman','women','man','men','boy','girl','racket','bathroom','scissors','vase','santa','flock','walking','parking','horse','front','pair','group','living','their','photo','one','two','three','four','reading','blurry','image','picture','each','to','laying','says','next','riding','looking','wearing','top','jumping','end','sitting','person','couple','sitting','standing','running','his','her','in','it','down','close','up','and','on','wii','with','that','at','using','eating','brushing','of','the','are','a','an','taking','holding','playing','talking']\n",
    "    file = open(r\"final_cap1.txt\", 'w')\n",
    "\n",
    "    unique_words = set(word_list)\n",
    "    for word in unique_words:\n",
    "        if word not in useless:\n",
    "            file.write(str(word) + \"\\n\")\n",
    "        \n",
    "   # def convert(word_list):\n",
    "    #    return (word_list[0].split())\n",
    "   # print(convert(word_list), sep=\"\\n\")\n",
    "\n",
    "unique_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_file():\n",
    "    input_file = open(r\"a-PyTorch-Tutorial-to-Image-Captioning/caption.txt\", 'r')\n",
    "    file_contents = input_file.read()\n",
    "    input_file.close()\n",
    "    word_list = file_contents.split()\n",
    "    useless=['red','for','preparing','screen','line','lit','dimly','kinds','bikini','different','shaped','beautiful','pile','stop','stuffed','topped','neon','slicing','like','types','items','wooden','stack','small','many','sleeping','pairs','smile','short','silhouette','cooking','dark','legs','palm','light','smart','purple','kids','box','lot','other','open','signs','girls','brown','boys','herself','cat','various','tall','display','very','nintendo','near','board','covered','smiling','while','potted','large','lots','cutting','parked','train','small','blow','over','performing','horses','big','little','elephants','bear','drying','himself','blue','piece','sticker','some','furniture','filled','yellow','of','from','pink','through','reads','doorway','doing','table','middle','hand','court','posing','white','child','projection','beard','cloudy','cell','glass','flying','hot','plate','bench','plane','growing','silver','view','glasses','chair','shirt','out','persons','green','game','side','dining','bed','bears','remote','teeth','bat','game','video','flower','teddy','cap','hat','driving','suit','suits','little','tiled','book','mirror','black','start','is','sticking','flowers','rear','meter','tilted','skate','back','has','around','sign','desk','tongue','birds','clock','plane','room','himself','couch','control','giraffe','young','its','tennis','brushes','toothbrush','baseball','bird','across','racquet','people','bowl','bunch','clear','crowd','tooth','urinals','woman','women','man','men','boy','girl','racket','bathroom','scissors','vase','santa','flock','walking','parking','horse','front','pair','group','living','their','photo','one','two','three','four','reading','blurry','image','picture','each','to','laying','says','next','riding','looking','wearing','top','jumping','end','sitting','person','couple','sitting','standing','running','his','her','in','it','down','close','up','and','on','wii','with','that','at','using','eating','brushing','of','the','are','a','an','taking','holding','playing','talking']\n",
    "    file = open(r\"final_cap1.txt\", 'w')\n",
    "\n",
    "    unique_words = set(word_list)\n",
    "    for word in unique_words:\n",
    "        if word not in useless:\n",
    "            file.write(str(word) + \"\\n\")\n",
    "        \n",
    "    \n",
    "unique_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_folder(Video_folder):\n",
    "    \n",
    "    #os.makedirs(\"output\")\n",
    "    try:\n",
    "        for i, Video_name in enumerate(os.listdir(Video_folder)):\n",
    "                #keyframe_folder = \"keyframes/\" + str(i)\n",
    "                print(Video_name)\n",
    "                vf.extract_keyframes(os.path.join(Video_folder, Video_name))\n",
    "                print(\"Extraction complete!!\")\n",
    "                for count, filename in enumerate(os.listdir(\"vdos/keyframes\")):\n",
    "                    str_name = filename.split('.')\n",
    "                    n = int(str_name[0])\n",
    "                    a = str(n/25)\n",
    "                    seconds_input, b = a.split('.')\n",
    "                    if len(b)==1:\n",
    "                        b = b + \"00\"\n",
    "                    elif len(b)==2:\n",
    "                        b = b + \"0\"\n",
    "                    else:\n",
    "                        b = b\n",
    "                    converted_time = datetime.timedelta(seconds=int(seconds_input))\n",
    "                    total = str(converted_time).split(\":\")\n",
    "                    total.append(b)\n",
    "                    hour = total[0]\n",
    "                    if len(hour)==1:\n",
    "                        hour = \"0\" + hour\n",
    "                    else:\n",
    "                        hour = hour\n",
    "                    total[0] = hour\n",
    "                    new_name = '-'.join(total)\n",
    "                    frame_loc = os.path.join(\"vdos/keyframes\", filename) \n",
    "                    \n",
    "                    dst = os.path.join(\"vdos/keyframes\", new_name) + \".jpg\" \n",
    "                    try :\n",
    "                        os.rename(frame_loc, dst)\n",
    "                        print(\"Source path renamed to destination path successfully.\")\n",
    "                    except IsADirectoryError:\n",
    "                        print(\"Source is a file but destination is a directory.\")\n",
    "                    except NotADirectoryError:\n",
    "                        print(\"Source is a directory but destination is a file.\")\n",
    "                    except PermissionError:\n",
    "                        print(\"Operation not permitted.\")\n",
    "                    except OSError as error:\n",
    "                        print(error)\n",
    "    \n",
    "                os.rename(\"vdos/keyframes\", \"output/\"+ Video_name.split(\".\")[0])\n",
    "                print(\"Folder successfully renamed\")\n",
    "    except:\n",
    "            print(\"exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mirzapur.mp4\n",
      "!!! The output directory 'keyframes' is not empty. No iframes were extracted. !!!\n",
      "Extraction complete!!\n",
      "exit\n"
     ]
    }
   ],
   "source": [
    "rename_folder(\"/Users/toshiniagrawal/Desktop/kamalini_keyframes/a-PyTorch-Tutorial-to-Image-Captioning/vdos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save('BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar','/Users/toshiniagrawal/Desktop/kamalini_keyframes/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-113-f36f863eb773>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-113-f36f863eb773>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    torch.load with map_location=torch.device('cpu')\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "torch.load with map_location=torch.device('cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    map_location=lambda storage, loc: storage.cuda()\n",
    "else:\n",
    "    map_location='cpu'\n",
    "    \n",
    "checkpoint = torch.load('/Users/toshiniagrawal/Desktop/kamalini_keyframes/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar', map_location=map_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Module.dump_patches = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (<ipython-input-114-368c38c0219b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-114-368c38c0219b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    torch.cuda.is_available()= True\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-fb85458d6508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/toshiniagrawal/Desktop/kamalini_keyframes/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model = torch.load('/Users/toshiniagrawal/Desktop/kamalini_keyframes/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-5d573a5e1b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/toshiniagrawal/Desktop/kamalini_keyframes/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "torch.save('BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar'.state_dict(), '/Users/toshiniagrawal/Desktop/kamalini_keyframes/BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"caption.py\", line 241, in <module>\r\n",
      "    coco()\r\n",
      "  File \"caption.py\", line 208, in coco\r\n",
      "    decoder = checkpoint['decoder']\r\n",
      "TypeError: string indices must be integers\r\n"
     ]
    }
   ],
   "source": [
    "!python caption.py --img_folder='vdos/keyframes' --model='BEST_checkpoint_coco_5_cap_per_img_5_min_word_freq.pth.tar' --word_map='WORDMAP_coco_5_cap_per_img_5_min_word_freq.json' --beam_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_file():\n",
    "    input_file = open(r\"a-PyTorch-Tutorial-to-Image-Captioning/caption.txt\", 'r')\n",
    "    file_contents = input_file.read()\n",
    "    input_file.close()\n",
    "    word_list = file_contents.split()\n",
    "    useless=['red','for','preparing','screen','line','lit','dimly','kinds','bikini','different','shaped','beautiful','pile','stop','stuffed','topped','neon','slicing','like','types','items','wooden','stack','small','many','sleeping','pairs','smile','short','silhouette','cooking','dark','legs','palm','light','smart','purple','kids','box','lot','other','open','signs','girls','brown','boys','herself','cat','various','tall','display','very','nintendo','near','board','covered','smiling','while','potted','large','lots','cutting','parked','train','small','blow','over','performing','horses','big','little','elephants','bear','drying','himself','blue','piece','sticker','some','furniture','filled','yellow','of','from','pink','through','reads','doorway','doing','table','middle','hand','court','posing','white','child','projection','beard','cloudy','cell','glass','flying','hot','plate','bench','plane','growing','silver','view','glasses','chair','shirt','out','persons','green','game','side','dining','bed','bears','remote','teeth','bat','game','video','flower','teddy','cap','hat','driving','suit','suits','little','tiled','book','mirror','black','start','is','sticking','flowers','rear','meter','tilted','skate','back','has','around','sign','desk','tongue','birds','clock','plane','room','himself','couch','control','giraffe','young','its','tennis','brushes','toothbrush','baseball','bird','across','racquet','people','bowl','bunch','clear','crowd','tooth','urinals','woman','women','man','men','boy','girl','racket','bathroom','scissors','vase','santa','flock','walking','parking','horse','front','pair','group','living','their','photo','one','two','three','four','reading','blurry','image','picture','each','to','laying','says','next','riding','looking','wearing','top','jumping','end','sitting','person','couple','sitting','standing','running','his','her','in','it','down','close','up','and','on','wii','with','that','at','using','eating','brushing','of','the','are','a','an','taking','holding','playing','talking']\n",
    "    file = open(r\"final_cap1.txt\", 'w')\n",
    "\n",
    "    unique_words = set(word_list)\n",
    "    for word in unique_words:\n",
    "        if word not in useless:\n",
    "            file.write(str(word) + \"\\n\")\n",
    "        \n",
    "    \n",
    "unique_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
